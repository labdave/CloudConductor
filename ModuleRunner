#!/usr/bin/env python3

import sys
import os
import resource
import argparse
import logging
import json
import importlib
import subprocess as sp

from System import GAPipeline
from System.Datastore import GAPFile
from Config import CustomFormatter
from Aries.outputs import PackageLogFilter
from Modules import Module, Splitter, Merger, PseudoMerger
from inspect import signature

def __load_module(module_name, submodule=None, module_args=None):

        # Try importing the module
        try:
            _module = importlib.import_module(module_name)
        except:
            logging.error("Module %s could not be imported! "
                          "Check the module name spelling and ensure the module exists." % module_name)
            raise

        # Check to see if submodule actually exists
        submodule = module_name if submodule is None else submodule
        if submodule not in _module.__dict__:
            logging.error("Module '%s' was successfully imported, but does not contain submodule '%s'! "
                          "Check the submodule spelling and ensure the submodule exists in the module." % (module_name, submodule))

            # Get list of available submodules
            available_modules = []
            for mod_name, mod in _module.__dict__.items():
                # Exclude any builtin types (start with _ or __),
                # Exclude imported modules that aren't classes (e.g. 'os' or 'logging')
                # Exclude anything that isn't a class (__class__.__name__ is None, e.g. __doc__, __package__)
                if mod_name.startswith("_") or mod.__class__.__name__ in [None, "module"]:
                    continue

                # Include anything that inherits from Module (with the exclusion of base classes (Module, Splitter, Merger)
                if issubclass(mod, Module) and mod_name not in ["Module", "Splitter", "Merger"]:
                    available_modules.append(mod_name)

            # Show available submodules in error message
            if len(available_modules) > 1:
                available_modules = ",".join(available_modules)
            elif len(available_modules) == 1:
                available_modules = available_modules[0]
            else:
                available_modules = "None"
            logging.error("Available submodules in module '%s':\n\t%s" % (module_name, available_modules))
            raise IOError("Invalid submodule '%s' specified for module '%s' in command args!" % (submodule,module_name))

        # Get the class
        _class = _module.__dict__[submodule]

        # Generate the module ID
        module_id = "%s" % (module_name)
        if submodule != module_name:
            module_id = "%s_%s" % (module_id, submodule)

        # Return instance of module class
        if "module_args" in signature(_class.__init__).parameters:
            return _class(module_id, False, module_args=module_args)
        return _class(module_id, False)

def __load_input_args(module, inputs):
    for input_type, input_arg in module.get_arguments().items():
            val = inputs[input_type] if input_type in inputs else None
            if val is None:
                val = input_arg.get_default_value()
            module.set_argument(input_type, val)
            logging.debug("Arg type: %s, val: %s" % (input_type, val))


def configure_argparser(argparser_obj):
    
    # Module to run
    argparser_obj.add_argument("-m", "--module",
                               action="store",
                               type=str,
                               dest='module',
                               required=True,
                               help="Module to run.")

    # Submodule to run
    argparser_obj.add_argument("-sm", "--submodule",
                               action="store",
                               type=str,
                               dest='submodule',
                               required=False,
                               help="Submodule to run.")

    # Module Arguments
    argparser_obj.add_argument("-inputs", "--module_inputs",
                               action="store",
                               type=str,
                               dest='module_inputs',
                               required=False,
                               help="Module inputs provided in JSON format.")

    # Module Arguments
    argparser_obj.add_argument("-args", "--module_args",
                               action="store",
                               type=str,
                               dest='module_args',
                               required=False,
                               help="Module arguments provided in JSON format.")

    # Read output file
    argparser_obj.add_argument("-ro", "--read_output",
                               action="store",
                               type=str,
                               dest='read_output',
                               required=False,
                               help="Argument used to flag the loading of a file for the output argument to a modules process_cmd_output function.")
    
    # Read error file
    argparser_obj.add_argument("-re", "--read_error",
                               action="store",
                               type=str,
                               dest='read_error',
                               required=False,
                               help="Argument used to flag the loading of a file for the error argument to a modules process_cmd_output function.")

    # Output dictionary file
    argparser_obj.add_argument("-o", "--output_file",
                               action="store",
                               type=str,
                               dest='output_file',
                               required=False,
                               help="File path specifiying where to save the defined outputs for the module after execution.")

    # Command definition file
    argparser_obj.add_argument("-c", "--command_file",
                               action="store",
                               type=str,
                               dest='command_file',
                               required=False,
                               help="File path specifiying where to save the command definition for the module.")

    # Verbosity level
    argparser_obj.add_argument("-v",
                               action='count',
                               dest='verbosity_level',
                               required=False,
                               default=0,
                               help="Increase verbosity of the program."
                                    "Multiple -v's increase the verbosity level:\n"
                                    "   0 = Errors\n"
                                    "   1 = Errors + Warnings\n"
                                    "   2 = Errors + Warnings + Info\n"
                                    "   3 = Errors + Warnings + Info + Debug")


def configure_logging(verbosity):
    # configure log handlers
    th = logging.StreamHandler()
    if sys.stderr.isatty():
        th.setFormatter(CustomFormatter())
    else:
        th.setFormatter(CustomFormatter(use_colors=False))

    fh = logging.FileHandler("module_runner_log.txt", 'w+')
    fh.setFormatter(CustomFormatter(use_colors=False))

    # Configuring the logging system to the lowest level
    logging.basicConfig(level=logging.DEBUG, handlers=[fh, th])

    # Setting the level of the logs
    level = [logging.ERROR, logging.WARNING, logging.INFO, logging.DEBUG][verbosity]
    logger = logging.getLogger()
    logger.setLevel(level)
    # Filter the logs.
    # Logs not from the CC package will be discarded
    log_filter = PackageLogFilter(packages=["CloudConductor"])
    for handler in logger.handlers:
        handler.addFilter(log_filter)


def configure_import_paths():

    # Get the directory of the executable
    exec_dir = os.path.dirname(__file__)

    # Add the modules paths to the python path
    sys.path.insert(1, os.path.join(exec_dir, "Modules/Tools/"))
    sys.path.insert(1, os.path.join(exec_dir, "Modules/Splitters/"))
    sys.path.insert(1, os.path.join(exec_dir, "Modules/Mergers/"))


def update_log_command(command, module):
    # Generating all the logging pipes
    log_cmd_null    = f" |& tee -a /dev/null"
    log_cmd_stdout  = f" | tee -a /data/log/{module}.log"
    log_cmd_stderr  = f" > >(tee -a /dev/null) 2> >(tee -a /data/log/{module}.log >&2)"
    log_cmd_all     = f" |& tee -a /data/log/{module}.log"

    # Replacing the placeholders with the logging pipes
    command = command.replace("!LOG0!", log_cmd_null)
    command = command.replace("!LOG1!", log_cmd_stdout)
    command = command.replace("!LOG2!", log_cmd_stderr)
    command = command.replace("!LOG3!", log_cmd_all)


def main():

    # Configure argparser
    argparser = argparse.ArgumentParser(formatter_class=argparse.RawTextHelpFormatter)
    configure_argparser(argparser)

    # Parse the arguments
    args = argparser.parse_args()

    # Configure logging
    configure_logging(args.verbosity_level)

    # Configuring the importing locations
    configure_import_paths()

    # Initialize variables
    err     = True
    err_msg = None

    try:
        if args.submodule == "None":
            args.submodule = None

        module = __load_module(args.module, args.submodule, args.module_args)

        if args.module_inputs:
            inputs = json.loads(args.module_inputs)
            __load_input_args(module, inputs)

        module_command = module.get_command()

        update_log_command(module_command, args.module)

        # if flag set to save command, get command and save it to the specified file
        if args.command_file:
            with open(args.command_file, 'w') as command_file:
                if module_command:
                    command_file.write(module_command)
                else:
                    command_file.write("")
        
        # if output or error text files provided process them with the module's process_cmd_output function
        if args.read_output or args.read_error:
            output_text = ""
            error_text = ""
            if args.read_output:
                with open(args.read_output, 'r') as out_file:
                    output_text = out_file.read()
            if args.read_error:
                with open(args.read_error, 'r') as err_file:
                    error_text = err_file.read()
            module.process_cmd_output(output_text, error_text)

        # if flag for saving the output definitions is set, save the output keys to the specified file
        if args.output_file:
            output_dict = module.get_output()
            for k, v in output_dict.items():
                if isinstance(v, GAPFile):
                    output_dict[k] = v.path
            with open(args.output_file, 'w') as output_file:
                output_file.write(json.dumps(output_dict))

        # Indicate that pipeline completed successfully
        err = False

    except BaseException as e:
        import traceback
        logging.error("ModuleRunner failed!")
        err_msg = "%s\n%s" % (e, traceback.format_exc())
        logging.error("ModuleRunner failure error:\n%s" % err_msg)
        raise

    finally:
        sys.exit()

if __name__ == "__main__":
    main()
